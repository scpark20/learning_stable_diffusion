{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3794e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoencoderKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d87c034c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict([('in_channels', 3),\n",
       "            ('out_channels', 3),\n",
       "            ('down_block_types',\n",
       "             ('DownEncoderBlock2D',\n",
       "              'DownEncoderBlock2D',\n",
       "              'DownEncoderBlock2D',\n",
       "              'DownEncoderBlock2D')),\n",
       "            ('up_block_types',\n",
       "             ('UpDecoderBlock2D',\n",
       "              'UpDecoderBlock2D',\n",
       "              'UpDecoderBlock2D',\n",
       "              'UpDecoderBlock2D')),\n",
       "            ('block_out_channels', (128, 256, 512, 512)),\n",
       "            ('layers_per_block', 2),\n",
       "            ('act_fn', 'silu'),\n",
       "            ('latent_channels', 4),\n",
       "            ('norm_num_groups', 32),\n",
       "            ('sample_size', 512),\n",
       "            ('scaling_factor', 0.18215),\n",
       "            ('force_upcast', True),\n",
       "            ('_use_default_values',\n",
       "             ['force_upcast', 'norm_num_groups', 'act_fn'])])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = AutoencoderKL.from_single_file('/data/sd_files/checkpoint/beautifulRealistic_v7.safetensors', use_safetensors=True)\n",
    "vae.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46f4d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = AutoencoderKL(\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    down_block_types=('DownEncoderBlock2D',),\n",
    "    up_block_types=('UpDecoderBlock2D',),\n",
    "    block_out_channels=(64,),\n",
    "    layers_per_block=1,\n",
    "    act_fn='silu',\n",
    "    latent_channels=4,\n",
    "    norm_num_groups=32,\n",
    "    sample_size=32,\n",
    "    scaling_factor=0.18215,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49132e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 32, 32]) torch.Size([2, 4, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.randn(2, 3, 32, 32)\n",
    "# Encoding\n",
    "posterior = vae.encode(x).latent_dist\n",
    "mu = posterior.mean\n",
    "logvar = posterior.logvar\n",
    "\n",
    "print(mu.shape, logvar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a215bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste",
   "language": "python",
   "name": "ste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
