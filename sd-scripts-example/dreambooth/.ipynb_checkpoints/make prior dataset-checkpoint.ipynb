{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f128f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 11 19:44:22 2024       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 4090        Off |   00000000:19:00.0 Off |                  Off |\r\n",
      "|  0%   52C    P8             39W /  450W |      11MiB /  24564MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 4090        Off |   00000000:68:00.0 Off |                  Off |\r\n",
      "|  0%   56C    P8             34W /  450W |      28MiB /  24564MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|    0   N/A  N/A      1212      G   /usr/lib/xorg/Xorg                              4MiB |\r\n",
      "|    1   N/A  N/A      1212      G   /usr/lib/xorg/Xorg                              9MiB |\r\n",
      "|    1   N/A  N/A      1491      G   /usr/bin/gnome-shell                            8MiB |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9617e1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scpark/anaconda3/envs/ste/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-11 19:44:25.107911: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 19:44:25.929965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/scpark/anaconda3/envs/ste/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/scpark/anaconda3/envs/ste/lib/python3.9/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scpark/anaconda3/envs/ste/lib/python3.9/site-packages/diffusers/configuration_utils.py:139: FutureWarning: Accessing config attribute `use_karras_sigmas` directly via 'DPMSolverSDEScheduler' object attribute is deprecated. Please access 'use_karras_sigmas' over 'DPMSolverSDEScheduler's config object instead, e.g. 'scheduler.config.use_karras_sigmas'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DDPMScheduler, DPMSolverSDEScheduler\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_single_file(\"/data/sd_files/checkpoint/beautifulRealistic_v7.safetensors\",\n",
    "                                                torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "\n",
    "pipe.to(\"cuda\")\n",
    "pipe.scheduler = DPMSolverSDEScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096b754e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a beautiful young woman with long hair and blue top',\n",
       " 'a young asian woman with long hair and earrings',\n",
       " 'a woman with long black hair and a white shirt',\n",
       " 'a woman with long black hair and a red dress',\n",
       " 'a young asian woman with long hair and a white shirt',\n",
       " 'a young woman with long black hair and a black top',\n",
       " 'a woman with long black hair and red lips',\n",
       " 'the korean actress is wearing earrings',\n",
       " 'a young woman with long hair and a white top',\n",
       " 'a beautiful young woman with long black hair and a white top',\n",
       " 'a woman with long black hair and a black bow tie',\n",
       " 'a young woman with long hair and an orange lipstick',\n",
       " 'a young asian woman with long black hair',\n",
       " 'a woman with long black hair and a black suit',\n",
       " 'a woman with long black hair wearing a tiara',\n",
       " 'a woman with long black hair and a red lipstick',\n",
       " 'the korean girl with long black hair and earrings',\n",
       " 'a beautiful young woman with long hair wearing a white blazer',\n",
       " 'a beautiful young woman with long brown hair and brown eyes',\n",
       " 'a woman with long hair and a black top',\n",
       " 'a woman with long black hair and red lips',\n",
       " 'a woman with long black hair posing for a photo',\n",
       " 'a young woman with long hair and a white dress',\n",
       " 'a young woman with long black hair and a white top',\n",
       " 'a woman with a white shirt and earrings',\n",
       " 'a woman with long black hair and a pink lipstick',\n",
       " 'a beautiful asian woman with red lipstick']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def read_txt_files_in_directory(directory_path):\n",
    "    all_files_content = []\n",
    "\n",
    "    # 디렉토리 내 모든 파일을 확인\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # .txt 파일만 처리\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                file_content = f.readline().strip()\n",
    "                all_files_content.append(file_content.replace('jisoo, ', ''))\n",
    "\n",
    "    return all_files_content\n",
    "\n",
    "# 사용 예제\n",
    "directory_path = \"/data/sd-dataset/jisoo_png\"\n",
    "files_content = read_txt_files_in_directory(directory_path)\n",
    "\n",
    "files_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/500 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|██▏                                         | 1/20 [00:00<00:05,  3.21it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  7.34it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:01, 10.09it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:00<00:01, 11.13it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:00<00:00, 12.61it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = '/data/sd-dataset/prior'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "for i in tqdm(range(500)):\n",
    "    prompt = files_content[np.random.randint(0, len(files_content))]\n",
    "    image = pipe(prompt=prompt,\n",
    "                 height=512,\n",
    "                 width=512,\n",
    "                 num_inference_steps=20,\n",
    "                 guidance_scale=7,\n",
    "                ).images[0]\n",
    "    image.save(os.path.join(save_dir, str(i) + '.png'))\n",
    "    \n",
    "    with open(os.path.join(save_dir, str(i) + '.txt'), 'w') as f:\n",
    "        f.write(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5872f31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352eaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ste",
   "language": "python",
   "name": "ste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
